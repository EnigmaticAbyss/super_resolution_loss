### Starting TaskPrologue of job 1010762 on tg095 at Sun 16 Mar 2025 01:24:33 PM CET
Running on cores 32-63 with governor ondemand
Sun Mar 16 13:24:33 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.86.15              Driver Version: 570.86.15      CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:41:00.0 Off |                    0 |
| N/A   36C    P0             56W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

/home/hpc/iwi5/iwi5255h/miniconda3/envs/SuperRes/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)

Starting Experiments...

Running Training with config: config/config_experiment1.yml
/home/hpc/iwi5/iwi5255h/miniconda3/envs/SuperRes/lib/python3.11/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Pretrained model found at saved_models/SwinIR_HieraPerceptualLoss.pth. Loading...
Error during training with config/config_experiment1.yml: 'model_state_dict'
Running Training with config: config/config_experiment16.yml
No pretrained model found at saved_models/SwinIR_HieraNoFreqPercepNoMSE.pth. Starting from scratch.
Starting Epoch 1/50
Training Epoch 1:   0%|          | 0/50 [00:00<?, ?it/s]Training Epoch 1:   2%|▏         | 1/50 [00:06<04:56,  6.04s/it]Training Epoch 1:   4%|▍         | 2/50 [00:08<03:04,  3.85s/it]Training Epoch 1:   6%|▌         | 3/50 [00:10<02:26,  3.12s/it]Training Epoch 1:   8%|▊         | 4/50 [00:12<02:09,  2.82s/it]Training Epoch 1:  10%|█         | 5/50 [00:15<01:58,  2.64s/it]Training Epoch 1:  12%|█▏        | 6/50 [00:17<01:49,  2.49s/it]Training Epoch 1:  14%|█▍        | 7/50 [00:19<01:43,  2.41s/it]Training Epoch 1:  16%|█▌        | 8/50 [00:22<01:41,  2.41s/it]Training Epoch 1:  18%|█▊        | 9/50 [00:24<01:37,  2.38s/it]Training Epoch 1:  20%|██        | 10/50 [00:26<01:34,  2.36s/it]Training Epoch 1:  22%|██▏       | 11/50 [00:28<01:29,  2.30s/it]Training Epoch 1:  24%|██▍       | 12/50 [00:31<01:26,  2.27s/it]Training Epoch 1:  26%|██▌       | 13/50 [00:33<01:26,  2.32s/it]Training Epoch 1:  28%|██▊       | 14/50 [00:35<01:23,  2.31s/it]Training Epoch 1:  30%|███       | 15/50 [00:38<01:20,  2.30s/it]Training Epoch 1:  32%|███▏      | 16/50 [00:40<01:18,  2.31s/it]Training Epoch 1:  34%|███▍      | 17/50 [00:42<01:16,  2.30s/it]Training Epoch 1:  36%|███▌      | 18/50 [00:44<01:12,  2.27s/it]Training Epoch 1:  38%|███▊      | 19/50 [00:47<01:11,  2.29s/it]Training Epoch 1:  40%|████      | 20/50 [00:49<01:08,  2.29s/it]Training Epoch 1:  42%|████▏     | 21/50 [00:51<01:06,  2.28s/it]Training Epoch 1:  44%|████▍     | 22/50 [00:54<01:04,  2.32s/it]Training Epoch 1:  46%|████▌     | 23/50 [00:56<01:01,  2.29s/it]Training Epoch 1:  48%|████▊     | 24/50 [00:58<00:59,  2.29s/it]slurmstepd: error: *** JOB 1010762 ON tg095 CANCELLED AT 2025-03-16T13:26:38 ***
=== JOB_STATISTICS ===
=== current date     : Sun 16 Mar 2025 01:26:41 PM CET
= Job-ID             : 1010762 on tinygpu
= Job-Name           : face
= Job-Command        : /home/woody/iwi5/iwi5255h/super_resolution_loss/run.sh
= Initial workdir    : /home/woody/iwi5/iwi5255h/super_resolution_loss
= Queue/Partition    : a100
= Slurm account      : iwi5 with QOS=normal
= Requested resources:  for 09:00:00
= Elapsed runtime    : 00:02:16
= Total RAM usage    : 1.1 GiB of requested  GiB (%)   
= Node list          : tg095
= Subm/Elig/Start/End: 2025-03-16T13:24:21 / 2025-03-16T13:24:21 / 2025-03-16T13:24:22 / 2025-03-16T13:26:38
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           26.1G   104.9G   209.7G        N/A      79K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
    /home/woody          8.1G  1000.0G  1500.0G        N/A   3,950    5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:41:00.0, 2663812, 17 %, 6 %, 16322 MiB, 64470 ms
